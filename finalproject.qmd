---
title: "Final Project"
author: "Majorz"
format: pdf
---

```{r read-data, message = F, warning = F}
library(tidyverse)
library(tidymodels)
library(glmnet)
library(Stat2Data)
library(ggcorrplot)
library(ggfortify)
spotify <- read_csv("data/tf_mini.csv")
```

## Introduction and Data

With recent features on music apps such as Spotify Wrapped gaining massive popularity, understanding users' music taste for personalized recommendations and music trend analysis have become a critical challenge for streaming companies. To categorize and analyze the countless songs on these platforms, each are dissected into various musical elements ranging from duration and tempo to loudness and danceability. Using a real database of song tracks compiled and released by Spotify for data engineering purposes, we wanted to see whether common trends could be observed between different musical elements. Modes of songs, specifically, were of our interest since they determine the mood of the music --- songs in major modes sound more bright and uplifting while those in minor modes are more calm and even sadder. We wanted to explore if musical aspects such as bounciness or tempo would be correlated to the song's mode in some way, with some of our example hypotheses being that minor songs would be slower and/or less danceable but more acoustic than major songs. Hence, we set the following:

Research question: How do different musical elements affect whether a song is in major or minor mode?

This data was collected from the Spotify for Developers website, as the data set was published to be used as part of an open data science challenge. With no null values and well-categorized variables, our data was already cleaned and ready to be used for a complete case analysis. Minor data cleaning processes that we conducted were deleting irrelevant variables such as acoustic vectors and adding a new variable "new_mode" to express major and minor modes numerically as 1 and 0.

Data source: https://www.aicrowd.com/challenges/spotify-sequential-skip-prediction-challenge/dataset_files (need to create an account and log in to access the dataset)

Some of our key variables included:

-   duration: length of the song in seconds
-   release_year: year of song released
-   key: song key starting from C major (0) to B minor (11)
-   mode: song mode (major or minor)
-   new_mode: song mode numerized (1 = major, 0 = minor)
-   tempo: speed of song in beats per minute (bpm)
-   time signature: number of quarter notes in each measure

To get a gist of what our data was presenting, we fitted an initial logistic model using all variables as predictors.

```{r logistic-model, message = F, warning = F}
spotify_mode <- spotify |>
  mutate(new_mode = if_else(mode == "major", 1, 0), 
         new_mode = as.numeric(new_mode))

spotify_mode |> drop_na(new_mode)

glm_all_mode <- glm(new_mode ~ us_popularity_estimate + duration + release_year + acousticness + 
     beat_strength + bounciness + danceability + dyn_range_mean + energy + 
     flatness + instrumentalness + key + liveness + loudness + mechanism + 
       organism + speechiness + tempo + time_signature + valence,
     data = spotify_mode,
     family = "binomial")
summary(glm_all_mode)
```

As demonstrated by the regression model above, there are many predictors that are statistically significant, using the significance level of $\alpha=0.5$. However, it is critical to improve this baseline model in the following ways:

1)  Confirm that there are not instances of multicollinearity (or model overfitting)
2)  Ensure that the variables included are meaningfully contributing to the model
3)  Optimize the model and determine if interactions or changes are appropriate

```{r corplotvars, message = F, warning = F}
spotify_cor <- spotify_mode|>
  select(us_popularity_estimate, duration, release_year, acousticness, 
     beat_strength, bounciness, danceability, dyn_range_mean, energy, 
     flatness,instrumentalness, key, liveness, loudness, mechanism, 
       organism, speechiness, tempo, time_signature, valence)

cor_spotify <- cor(spotify_cor)

ggcorrplot(cor_spotify)+
  labs(title = "Corrleation of Spotify Data Variables")
```

Source used: http://www.sthda.com/english/wiki/ggcorrplot-visualization-of-a-correlation-matrix-using-ggplot2#:\~:text=The%20easiest%20way%20to%20visualize,ggcorr()%20in%20ggally%20package

Examining the correlation plot above, it appears there are variables that have a high positive correlation with each other. This causes great concern with multicollinearity as the model may be overfitted. For example,

-   beat_strength is highly correlated with

    -   dyn_range_mean

    -   danceability

    -   bounciness

Therefore, to prevent overfitting in our regression model, the following variables should be removed:

1\) beat_strength

2\) dyn_range_mean

3\) bounciness

Note: We decided to leave in danceability because we felt that this would be be the best variable to include considering the four other variables.

The new regression model and corresponding correlation plot can be shown below:

```{r newcorplotvars, message = F, warning = F}
spotify_cor_new <- spotify_mode|>
  select(us_popularity_estimate, duration, release_year, acousticness, 
     beat_strength, danceability, energy, 
     flatness,instrumentalness, key, liveness, loudness, mechanism, 
       speechiness, tempo, time_signature, valence)

cor_spotify_new <- cor(spotify_cor_new)

ggcorrplot(cor_spotify_new)+
  labs(title = "Corrleation of Spotify Data Variables")
```

The new model:

```{r newlogistic-model, message = F, warning = F}

glm_final <- glm(new_mode ~ us_popularity_estimate + duration + release_year +
                          acousticness  + danceability  + energy + flatness + 
                          instrumentalness + key + liveness + loudness + mechanism + 
                          speechiness + tempo + time_signature + valence,
     data = spotify_mode,
     family = "binomial")
summary(glm_final)

```

Removing the highly related variables were essential to our analysis as some of the coefficients changed drastically, including changing direction (positive to negative)!

In addition to removing three variables due to extremely high correlations, it is also important to select variables that make an impact on the model. For example, some variables may be replicated or not meaningful by nature to the outcome of interest; therefore, removal is essential. In this analysis, we decided to use a LASSO model to select variables that are essential to the model.

```{r lasso, message = F, warning = F}
y <- spotify_mode$new_mode
x <- model.matrix(new_mode ~ us_popularity_estimate + duration + release_year + 
                  acousticness + danceability + energy + flatness + 
                  instrumentalness + key + liveness + loudness + mechanism + 
                  organism + speechiness + tempo + time_signature + valence,
                  data = spotify_mode, family = "binomial")
lasso_sc <- cv.glmnet(x, y, alpha = 1)
best_lambda <- lasso_sc$lambda.min
lasso_final <- glmnet(x, y, alpha = 1, lambda = best_lambda)
lasso_final$beta
```

LASSO kept all of the predictors.

```{r lasso-plot, message = F, warning = F}
plot(lasso_sc)
```

not sure if this is needed or not\^

## Methodology

Evaluating assumptions:

```{r}
spotify_test <- spotify |>
  mutate(new_mode = if_else(mode == "major", 1, 0), 
         new_mode = as.numeric(new_mode),
         speechiness_new = (speechiness)^2)

emplogitplot1(new_mode ~ (speechiness),
             data = spotify_test,
             ngroups = 20)
```


There had to be less data points for some of the predictors because there was only so many different values and enough of them to be able to get the empirical logits. For example, with key there is only 12 unique values, but not all of them had enough values to be calculated, so we did 10 groups. I eliminated the titles to make the plots more clear and because they were repetitive. In summary, we concluded that linearity is met for time signature, tempo, mechanism, loudness, liveness, instrumentalness, key, release year and popularity because there is no major pattern in empirical logits. Linearity was not met for valence, speechiness, organism, flatness, energy, danceability, acousticness and duration because they showed patterns in empirical logits.

These are potential limitations of these variables that do not meet the linarity assumption. However, since solving for linearity is sort of outside the scope of this course, we decided to leave the variables in the model. We do understand that there may be some linearity concerns when it comes to the overall view of our model.

```{r prediction-probability, message = F, warning = F, eval = F}
glm_aug <- glm_aug |>
  mutate(prob = exp(.fitted)/(1 + exp(.fitted)),
         pred_mode = ifelse(prob > 0.5, "Major", "Minor")) |>
  select(.fitted, prob, pred_mode, new_mode)

table(glm_aug$pred_mode, glm_aug$new_mode)
```

Using our logistic regression model as a classifier for any infection by using a threshold of 0.5 predicted probability, we are able to calculate the following values:

Prevalence:

Sensitivity: 29968/(29968 + 2587) = 0.921

Specificity: 3279/(3279 + 14870) = 0.181

Positive predicted value: 29968/(29968 + 14870) = 0.669

Negative predicted value: 3279/(3279 + 2587) = 0.559

This implies that \_\_\_

```{r roc-curve, message = F, warning = F, eval = FALSE}
glm_aug |>
  roc_curve(truth = as.factor(new_mode),
          prob,
          event_level = "second") |>
  autoplot()

glm_aug |>
  roc_auc(truth = as.factor(new_mode),
          prob,
          event_level = "second")
```

## Results

One predictor that makes sense to interpret is key because key has changes in whole numbers while many of the other predictors are within tenths of differences of each other amongst observations. Holding all other predictors constant, for every one (unit) increase in key, we expect the log-odds of a song being major rather than minor to increase by approximately 0.0931. So, when holding all other predictors constant, we for every one number increase in key (find what this means), the odds of the patient getting any infection is predicted to be multiplied by $e^{0.0931}$ = 1.0976. For an example, while holding all other predictors constant, the relative odds of a song being major rather than minor comparing a song with key 10 vs a song with key 2 is $e^{8*0.0931}$ is 2.106.

to be continued

## Discussion

In conclusion, this model has benefits and shortfalls. Primarily, it is clear that there are variables that do not meet the linearity assumption and create difficulties for interpretation. Additionally, there are challenges with some of the variables in terms of their scaling. For example, the variable us_popularity_estimate mostly takes on values from 97-99. This is the case with many variables within the data. Therefore, our model does have downfalls, but it does have an interpretive aspect that is desirable. For example, there are not any sophisticated transformations on the predictors. This allows the results to be more "reasonable" in terms of extrapolation and interpretation. Although this may not be the "best" and most statistically complete model, it is effective in providing meaningful results while simultaneously maintaining an applicative aspect.



```{r linearity-check, message = F, warning = F, echo = FALSE, eval = FALSE}
glm_aug <- augment(glm_all_mode)

emplogitplot1(new_mode ~ us_popularity_estimate,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ duration,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ release_year,
             data = spotify_mode,
             ngroups = 5)
emplogitplot1(new_mode ~ acousticness,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ danceability,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ energy,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ flatness,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ instrumentalness,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ key,
             data = spotify_mode,
             ngroups = 10)
emplogitplot1(new_mode ~ liveness,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ loudness,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ mechanism,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ speechiness,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ tempo,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ time_signature,
             data = spotify_mode,
             ngroups = 2)
emplogitplot1(new_mode ~ valence,
             data = spotify_mode,
             ngroups = 20)
```

