---
title: "Final Project"
author: "Majorz"
format: pdf
---

```{r read-data, message = F, warning = F, echo = FALSE}
library(tidyverse)
library(tidymodels)
library(glmnet)
library(Stat2Data)
library(ggcorrplot)
library(ggfortify)
spotify <- read_csv("data/tf_mini.csv")
```

## Introduction and Data

With recent features on music apps such as Spotify Wrapped gaining massive popularity, understanding users' music taste for personalized recommendations and music trend analysis have become a critical challenge for streaming companies. To categorize and analyze the countless songs on these platforms, each are dissected into various musical elements ranging from duration and tempo to loudness and danceability. Using a real database of song tracks compiled and released by Spotify for data engineering purposes, we wanted to see whether common trends could be observed between different musical elements. Modes of songs, specifically, were of our interest since they determine the mood of the music --- songs in major modes sound more bright and uplifting while those in minor modes are more calm and even sadder. We wanted to explore if musical aspects such as bounciness or tempo would be correlated to the song's mode in some way, with some of our example hypotheses being that minor songs would be slower and/or less danceable but more acoustic than major songs. Hence, we set the following: *How do different musical elements affect whether a song is in major or minor mode?*

This data was collected from the Spotify for Developers website, as the data set was published to be used as part of an open data science challenge. With no null values and well-categorized variables, our data was already cleaned and ready to be used for a complete case analysis. Minor data cleaning processes that we conducted were deleting irrelevant variables such as acoustic vectors and adding a new variable "new_mode" to express major and minor modes numerically as 1 and 0. Key variables included:

|                                                          |                                                             |                                                             |
|-----------------------|------------------------|------------------------|
| **release_year**: year of song released (1950-2018)      | **key**: song key starting from C major (0) to B minor (11) | **mode**: song mode (major or minor)                        |
| **new_mode**: song mode numerized (1 = major, 0 = minor) | **tempo**: speed of song in beats per minute (bpm)          | **time signature**: number of quarter notes in each measure |

To get a gist of what our data was presenting, we fitted an initial logistic model using all variables as predictors.

```{r initialeda, message = F, warning = F, echo = FALSE}
spotify_mode <- spotify |>
  mutate(new_mode = if_else(mode == "major", 1, 0), 
         new_mode = as.numeric(new_mode))
```

```{r logisticmodel, message = F, warning = F, echo = FALSE}
glm_all_mode <- glm(new_mode ~ us_popularity_estimate + duration + 
                      release_year + acousticness + beat_strength + 
                      bounciness + danceability + dyn_range_mean + 
                      energy + flatness + instrumentalness + key + 
                      liveness + loudness + mechanism + organism + 
                      speechiness + tempo + time_signature + valence,
     data = spotify_mode,
     family = "binomial")
summary(glm_all_mode)$coef
```

As demonstrated by the regression model above, there are many predictors that are statistically significant, using the significance level of $\alpha=0.5$. However, it is critical to improve this baseline model in the following ways:

1)  Confirm that there are not instances of multicollinearity (or model overfitting)
2)  Ensure that the variables included are meaningfully contributing to the model
3)  Optimize the model and determine if tranformations or changes are appropriate

```{r corplotvars, message = F, warning = F, echo = FALSE}
spotify_cor <- spotify_mode|>
  dplyr::select(us_popularity_estimate, duration, release_year, acousticness, 
     beat_strength, bounciness, danceability, dyn_range_mean, energy, 
     flatness,instrumentalness, key, liveness, loudness, mechanism, 
       organism, speechiness, tempo, time_signature, valence)

cor_spotify <- cor(spotify_cor)

ggcorrplot(cor_spotify)+
  labs(title = "Corrleation of Spotify Data Variables")
```

Examining the correlation plot above, it appears there are variables that have a high positive correlation with each other. This causes great concern with multicollinearity as the model may be overfitted. For example,

-   beat_strength is highly correlated with, dyn_range_mean, danceability, and bounciness
-   mechanism is highly correlated with organism

Therefore, to prevent overfitting in our regression model, the following variables should be removed - beat_strength, dyn_range_mean, bounciness, and organism. However, we decided to leave in danceability and mechanism because we felt that these variables are easily understandable from a musical perspective and may be important to the model. (A revised correlation plot can be found in the appendix)

The new model:

```{r newlogistic-model, message = F, warning = F, echo = FALSE}
glm_final <- glm(new_mode ~ us_popularity_estimate + duration + release_year +
                          acousticness  + danceability  + energy + flatness + 
                          instrumentalness + key + liveness + loudness + mechanism + 
                          speechiness + tempo + time_signature + valence,
     data = spotify_mode,
     family = "binomial")
summary(glm_final)$coef
```

Removing the highly related variables were essential to our analysis as some of the coefficients changed drastically, including changing signs (eg: danceability changed from a positive to negative contribution)! Additionally, the variable flatness is no longer significant in the model (at at 0.05 significance level).

In addition to removing removing the highly correlated variables, we felt it was also important to select variables that have the most impact on the model. For example, some variables may be not meaningful by nature to the outcome of interest; therefore, removal is essential. In this analysis, we decided to use a LASSO model to select variables.

```{r lasso, message = F, warning = F, echo = FALSE}
y <- spotify_mode$new_mode
x <- model.matrix(new_mode ~ us_popularity_estimate + duration + release_year + 
                  acousticness + danceability + energy + flatness + 
                  instrumentalness + key + liveness + loudness + mechanism + 
                  speechiness + tempo + time_signature + valence,
                  data = spotify_mode, family = "binomial")
lasso_sc <- cv.glmnet(x, y, alpha = 1)
best_lambda <- lasso_sc$lambda.min
lasso_final <- glmnet(x, y, alpha = 1, lambda = best_lambda)
lasso_final$beta
```

LASSO kept all of the predictors, demonstrating that the predictor variables are meaningfully contributing to our outcome of interest of whether the song is on a major/minor scale. It is important to note that LASSO does not include an intercept, as the model is centered. Since all variables are retained in the LASSO model, we decided to use the **standard logistic model** instead of the LASSO model for further analysis because of the adjusted coefficients and inclusion of an intercept.

## Methodology

In order to ensure our model can be interpreted in a real-world context, it is critical to check all of the assumptions for a logistic model. For logistic regression, the two most important assumptions are independence and linearity. For independence, we are checking to see if each observation in our data is independent from each other (eg: knowing about one observation does not tell us about another). On the other hand, linearity for logistic models ensures that the predictor variables generally follow a linear trend with the odds of the outcome of interest. There should not be any clear patterns or distinct trends within the data.

**Independence:**

the *observations* are independent from each other (careful - *not* the predictors)

**Linearity:**

```{r linearity-issue, message = F, warning = F, echo = FALSE}
glm_aug <- augment(glm_final)

spotify_test <- spotify |>
  mutate(new_mode = if_else(mode == "major", 1, 0), 
         new_mode = as.numeric(new_mode),
         speechiness_new = (speechiness)^2)

emplogitplot1(new_mode ~ (speechiness),
             data = spotify_test,
             ngroups = 20)
```

There were fewer data points for some of the predictors because there was only so many different values and enough of them to be able to get the empirical logits. For example, with key there is only 12 unique values, but not all of them had enough values to be calculated, so we did 10 groups. I eliminated the titles to make the plots more clear and because they were repetitive. In summary, we concluded that linearity is met for time signature, tempo, mechanism, loudness, liveness, instrumentalness, key, release year and popularity because there is no major pattern in empirical logits. Linearity was not met for valence, speechiness, organism, flatness, energy, danceability, acousticness and duration because they showed patterns in empirical logits.

These are potential limitations of these variables that do not meet the linearity assumption. One issue that was tricky is attempting to transform the variables that had underlying trends. Unfortunately, we were unable to make a substantial impact, especially on the speechiness variable. However, upon further research, we discovered that the variable is impacted strongly by songs that are instrumental, as they cause a cluster of points around 0 (demonstrated on the empirical logit plot). Therefore, it is critical to understand that there may be some linearity concerns when it comes to the overall view of our model.

```{r prediction-probability, message = F, warning = F, echo = FALSE}
glm_aug <- glm_aug |>
  mutate(prob = exp(.fitted)/(1 + exp(.fitted)),
         pred_mode = ifelse(prob > 0.5, "Major", "Minor")) |>
  dplyr::select(.fitted, prob, pred_mode, new_mode)

table(glm_aug$pred_mode, glm_aug$new_mode)
```

Using our logistic regression model as a classifier for any infection by using a threshold of 0.5 predicted probability, we are able to calculate the following values:

Prevalence:

Sensitivity: 29968/(29968 + 2587) = 0.921

Specificity: 3279/(3279 + 14870) = 0.181

Positive predicted value: 29968/(29968 + 14870) = 0.669

Negative predicted value: 3279/(3279 + 2587) = 0.559

This implies that \_\_\_

```{r roc-curve, message = F, warning = F, echo = FALSE, fig.width=3, fig.height=3}
glm_aug |>
  roc_curve(truth = as.factor(new_mode),
          prob,
          event_level = "second") |>
  autoplot()

glm_aug |>
  roc_auc(truth = as.factor(new_mode),
          prob,
          event_level = "second")
```

The value of the area under the curve of the ROC curve is 0.64. Although it is greater than 0.5, which would imply that it would be just as effective to guess the major/minor scale, it is not as high as expected. As discussed below, there may be several reasons that this occurs in our model.

## Results

One predictor that is most aligned with our outcome variable (major/minor scale) is key because key has changes in whole numbers while many of the other predictors are within tenths of differences of each other amongst observations. Holding all other predictors constant, for every one (unit) increase in key, we expect the log-odds of a song being major rather than minor to increase by approximately 0.0931. So, when holding all other predictors constant, we for every one number increase in key (find what this means), the odds of the patient getting any infection is predicted to be multiplied by $e^{0.0931}$ = 1.0976. For an example, while holding all other predictors constant, the relative odds of a song being major rather than minor comparing a song with key 10 vs a song with key 2 is $e^{8*0.0931}$ is 2.106.

to be continued

## Discussion

\*\*\*\*\*\*\*\*\*TALK ABOUT WHAT WE LEARNED!!!!!!\*\*\*\*\*\*\*\*\*\*\*\*\*\*\* In conclusion, this model has benefits and shortfalls. Primarily, it is clear that there are variables that do not meet the linearity assumption and create difficulties for interpretation. For example, the variable speechiness, follows a distinct pattern. However, attempts to transform these variable were not effective because of underlying issues.

Additionally, there are challenges with some of the variables in terms of their scaling and units. For example, the variable us_popularity_estimate mostly takes on values from 97-99. Each variable is different, but they generally have unique scaling.

In all, our model does have downfalls, but it does have an interpretive aspect that is desirable. This allows the results to be more "reasonable" in terms of predicting if a song is in a major/minor key. The model, even though there are issues, is not extremely sophisticated or complex for a general audience. Even though the AUC value is not as strong as desirable, it is still an informative model. Generally, it provides insightful and meaningful results while simultaneously maintaining a real-world aspect.

In the future, we may want to explore other data sources and outcomes to understand the media market better. For example we could compare this data from Spotify with songs played on radio stations from the 1950's to current day. Would the popularity of songs on Spotify correspond with songs frequently played on the radio? There are many questions outside of our project scope that could be answered with further research and models.

## Appendix

Following are the empirical logit plots as referenced in the methodology section above.

```{r linearity-check, message = F, warning = F, echo = FALSE}

emplogitplot1(new_mode ~ us_popularity_estimate,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ duration,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ release_year,
             data = spotify_mode,
             ngroups = 5)
emplogitplot1(new_mode ~ acousticness,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ danceability,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ energy,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ flatness,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ instrumentalness,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ key,
             data = spotify_mode,
             ngroups = 10)
emplogitplot1(new_mode ~ liveness,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ loudness,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ mechanism,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ speechiness,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ tempo,
             data = spotify_mode,
             ngroups = 20)
emplogitplot1(new_mode ~ time_signature,
             data = spotify_mode,
             ngroups = 2)
emplogitplot1(new_mode ~ valence,
             data = spotify_mode,
             ngroups = 20)
```

New correlation plot after variables have been removed:

```{r newcorplotvars, message = F, warning = F, echo = FALSE}
spotify_cor_new <- spotify_mode|>
  dplyr::select(us_popularity_estimate, duration, release_year, acousticness, 
     beat_strength, danceability, energy, flatness,instrumentalness, key, 
     liveness, loudness, mechanism, speechiness, tempo, time_signature, valence)

cor_spotify_new <- cor(spotify_cor_new)

ggcorrplot(cor_spotify_new)+
  labs(title = "Corrleation of Spotify Data Variables")
```

## Citations

**Spotify data:**

https://www.aicrowd.com/challenges/spotify-sequential-skip-prediction-challenge/dataset_files (need to create an account and log in to access the dataset)

**Referenced for completing the correlation matrix:**

http://www.sthda.com/english/wiki/ggcorrplot-visualization-of-a-correlation-matrix-using-ggplot2#:\~:text=The%20easiest%20way%20to%20visualize,ggcorr()%20in%20ggally%20package
